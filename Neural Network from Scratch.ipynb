{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "333ebdfd-e928-4b8d-9f9d-38a02ab86ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rolling_df = pd.read_csv(\"matches (rolling stats).csv\")         ## Load the data\n",
    "\n",
    "training_data = rolling_df[rolling_df['date'] < '2024-06-01']   ## Training data from before date\n",
    "testing_data = rolling_df[rolling_df['date'] > '2024-06-01']    ## Testing data after date\n",
    "\n",
    "prediction_metrics = ['venue code', 'gf_rolling', 'sot_rolling', 'xg_strength']\n",
    "#prediction_metrics = ['venue code', 'xg_strength']\n",
    "#prediction_metrics = ['venue code',  'gf_rolling', 'sot_rolling']\n",
    "#prediction_metrics = ['gf_rolling']\n",
    "#prediction_metrics = ['xg_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8cdbc4aa-b907-42e6-b730-4e746f5dd511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "\n",
    "#################    Sigmoid function puts results between 0 - 1    #################\n",
    "def sigmoid(x):\n",
    "    S = 1 / (1+np.exp(-x))\n",
    "    return(S)\n",
    "\n",
    "#################    Softmax function noramlises results between 0 - 1    #################\n",
    "def softmax(x):\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    sigma = np.exp(x) / sum(np.exp(x))\n",
    "    return(sigma)\n",
    "\n",
    "#################    Relu function to set negative nodes to 0    #################\n",
    "def relu(z):          \n",
    "    out = np.maximum(0, z)\n",
    "    return(out)\n",
    "\n",
    "#################    Relu derivative function to produce binary nodes    #################\n",
    "def relu_derivative(y):\n",
    "    out = (y>0).astype(float)     ## if positive set to 1\n",
    "    return(out)\n",
    "    \n",
    "#################    Leaky Relu  function so small negative values can stay in the model    #################\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    y = np.where(x > 0, x, alpha * x)   \n",
    "    return(y)                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa178ba-6b30-4122-b4d5-e6700b3ae99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967b35b-df82-4cf8-ba84-695674991a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e3609ff-aa72-47ba-bb3e-4556881cc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_initialisation(number_of_hidden_layers, layer_sizes, input_size, output_size):\n",
    "\n",
    "    if len(layer_sizes) != number_of_hidden_layers:\n",
    "        print(f'layer sizes:{len(layer_sizes)}', f'number of layers:{number_of_hidden_layers}')\n",
    "        raise Exception(\"layer sizes must equal number of hidden layers\")\n",
    "        \n",
    "    layer_sizes.append(output_size)      ## adds the output number of nodes to list of layer sizes\n",
    "    \n",
    "    ############# Creating initial weighting matrixes and biases ###############\n",
    "    \n",
    "    weighting_dict = {}                                             ## \n",
    "    bias_dict = {}                                               ## holds all the biases\n",
    "    for i in range(0, number_of_hidden_layers+1):                ## iterates through each possible layer connection\n",
    "    \n",
    "        if i == 0:          ## creating the first layer\n",
    "            xavier_weight_mat = np.random.uniform(-1/np.sqrt(input_size),1/np.sqrt(input_size), (layer_sizes[i], input_size))    ## xavier distribution    https://www.geeksforgeeks.org/xavier-initialization/\n",
    "        elif i < number_of_hidden_layers+2:  ## creating the middle layers\n",
    "            xavier_weight_mat = np.random.uniform(-1/np.sqrt(layer_sizes[i]),1/np.sqrt(layer_sizes[i]), (layer_sizes[i], layer_sizes[i-1]))\n",
    "       \n",
    "        bias = np.zeros((layer_sizes[i],1))\n",
    "        weighting_dict[f'layer_{i+1}'] = xavier_weight_mat      ## Appends the rand matrix to the layers dictionary\n",
    "        bias_dict[f'bias_{i+1}'] = bias\n",
    "    \n",
    "    return(weighting_dict, bias_dict)\n",
    "\n",
    "def node_activations(weighting_dict, bias_dict, training_data_row, prediction_metrics):\n",
    "\n",
    "    input_vector = training_data_row[prediction_metrics]\n",
    "    \n",
    "    pre_node_dict = {}                                 ## Creates empty dictionary for the pre node layers\n",
    "    act_node_dict = {}                                 ## Creates empty dictionary for the active node layers\n",
    "    counter = 1                                        ## Initialsies counter for calling dictionary items\n",
    "\n",
    "    pre_node_dict[f'node_0'] = input_vector  \n",
    "    \n",
    "    for item, weighting in weighting_dict.items():     ## item is the name of the dictionary item, value is the matrix assigned to the item\n",
    "       \n",
    "        if counter == 1:                               ## this deals with creating the first layer from input layer\n",
    "            pre_node = weighting @ input_vector        ## create the first layer \n",
    "            pre_node += bias_dict[f'bias_{counter}'].flatten()   ## add the bias to the first layer of pre activated nodes\n",
    "            \n",
    "            act_node = relu(pre_node)            ## activate the nodes\n",
    "            \n",
    "        else:\n",
    "            pre_node = weighting @ np.array(act_node_dict[f'node_{counter-1}']).flatten()    ## create the next layer using previous activation, sometimes ould create nested array so convert to array then flatten\n",
    "            pre_node += bias_dict[f'bias_{counter}'].flatten()           ## add the bias to the next layer\n",
    "    \n",
    "            if counter == len(weighting_dict):\n",
    "                act_node = softmax(pre_node)           ## if final node use softmax activation\n",
    "            else:\n",
    "                act_node = relu(pre_node)              ## otherwise use relu activation\n",
    "\n",
    "        pre_node_dict[f'node_{counter}'] = pre_node           ## Append each pre actiation node layer to dictionary\n",
    "        act_node_dict[f'node_{counter}'] = act_node           ## Append each activated node layer to dictionary\n",
    "    \n",
    "        counter += 1                                  ## Increment counter for dictionary extractions\n",
    "    \n",
    "    return(pre_node_dict, act_node_dict, bias_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b50a088e-dbf3-4c9e-ad03-7f15b4a35017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(training_data_row, weighting_dict, bias_dict, pre_node_dict, act_node_dict, output_size, learning_rate=0.0001):\n",
    "\n",
    "    blank = np.zeros((output_size,1))                 ## array of zeros of same size as output array\n",
    "    true = blank.copy()                               ## copy array of zeros\n",
    "    true[int(training_data_row['gf']), 0] = 1         ## creates vector of actual goals scored\n",
    "\n",
    "    ######################################### updating the weights #########################################\n",
    "    \n",
    "    alpha = learning_rate             ## alpha is set to the learning rate\n",
    "    count = len(weighting_dict)       ## initiasing count at max value\n",
    "    output = list(act_node_dict.values())[-1]\n",
    "    \n",
    "    updated_weighting_dict = {}\n",
    "    updated_bias_dict = {}\n",
    "    \n",
    "    for i in range(count,0,-1):\n",
    "        \n",
    "        if count == len(weighting_dict):           ## for the inital backpropagation from output layer\n",
    "            dl_dz =  output - true.flatten()       ## gradient wrt logits for softmax + CE loss\n",
    "        else:\n",
    "     \n",
    "            dl_dz = np.transpose(weighting_dict[f'layer_{count+1}']) @ dl_dz              ## first step of loss \n",
    "            dl_dz = np.multiply(dl_dz , relu_derivative(pre_node_dict[f'node_{count}']))  ## second step of element wise                         \n",
    "\n",
    "        if dl_dz.ndim == 1:                              ## if only 1 dimensional               \n",
    "            dl_dz = np.expand_dims(dl_dz, axis=1)        ## makes sure that its of the form (x,1) rather than (8,)\n",
    "\n",
    "        dl_db = dl_dz                 ##  biases independent of input activation so same as loss to pre node values\n",
    "        pre_node_dict[f'node_{count-1}'] = np.expand_dims(pre_node_dict[f'node_{count-1}'], axis =1)   ## dealing with array formatting\n",
    "        \n",
    "        dummy_weighting = weighting_dict[f'layer_{count}'] - alpha * (dl_dz @ np.transpose(pre_node_dict[f'node_{count-1}']) )   ## W = W - a*(dL/dW) = W - a*loss*input_into_node\n",
    "        dummy_bias = bias_dict[f'bias_{count}'] - alpha * dl_db    ## Create new updated bias\n",
    "    \n",
    "        updated_weighting_dict[f'layer_{count}'] = dummy_weighting     ## update the old weighting with the new weighting\n",
    "        updated_bias_dict[f'bias_{count}'] = dummy_bias               ## update the old bias with the new bias\n",
    " \n",
    "        count -= 1    ## increment the count by -1 to\n",
    "    \n",
    "    weighting_dict.update(updated_weighting_dict)     ## update the old weighting dictionary with the new dictionary\n",
    "    bias_dict.update(updated_bias_dict)               ## update the old bias dictionary with the new dictionary\n",
    "    \n",
    "    \n",
    "    return(weighting_dict, bias_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0381ace6-5d8d-4023-8e43-fcaf7ceaa6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each metric in the first layer is multiplied by the corresponding component for a weighting veector for each node ##\n",
    "## If we have 5 metrics and 10 first layer nodes then we need 10 vectors of size 5 ##\n",
    "## The first component of each of these 10 metrics contributes to the magnitude fo the first node, and so on ##\n",
    "## We need to start the initial vectors in some random state, limiting magnitudes of components to prevent vanishing/exploding ##\n",
    "\n",
    "\n",
    "def neural_network_processing(training_data, prediction_metrics, number_of_hidden_layers, layer_sizes, output_size, prev_weights=None, prev_biases=None):\n",
    "\n",
    "    input_size = len(prediction_metrics)\n",
    "\n",
    "    if (prev_weights == None) and (prev_biases == None):          ## run initilisation if no existing weights exist\n",
    "        weighting_dict, bias_dict = layer_initialisation(number_of_hidden_layers, layer_sizes, input_size, output_size)\n",
    "    else:                \n",
    "        weighting_dict, bias_dict = prev_weights, prev_biases    \n",
    "\n",
    "    for index, row in training_data.iterrows():     ## iterate through every row in the training data \n",
    "    \n",
    "        training_data_row = row  ## only need the prediciton metrics from each row    \n",
    "        pre_node_dict, act_node_dict, bias_dict = node_activations(weighting_dict, bias_dict, training_data_row, prediction_metrics) ## activate the nodes\n",
    "        weighting_dict, bias_dict = backpropagation(training_data_row, weighting_dict, bias_dict, pre_node_dict, act_node_dict, output_size, learning_rate=0.1) ## use backpropagation to update the weightings    \n",
    "\n",
    "    return(weighting_dict, bias_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf4bfb3a-89c7-4ffb-b37e-fb091637ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_process(weighting_dict, bias_dict, testing_data_row, prediction_metrics):\n",
    "\n",
    "    input_vector = testing_data_row[prediction_metrics]\n",
    "    \n",
    "    pre_node_dict = {}                                 ## Creates empty dictionary for the pre node layers\n",
    "    act_node_dict = {}                                 ## Creates empty dictionary for the active node layers\n",
    "    counter = 1                                        ## Initialsies counter for calling dictionary items\n",
    "\n",
    "    pre_node_dict[f'node_0'] = input_vector  \n",
    "    \n",
    "    for item, weighting in weighting_dict.items():     ## item is the name of the dictionary item, value is the matrix assigned to the item\n",
    "        \n",
    "        if counter == 1:                               ## this deals with creating the first layer from input layer\n",
    "            pre_node = weighting @ input_vector        ## create the first layer \n",
    "            pre_node += bias_dict[f'bias_{counter}'].flatten()   ## add the bias to the first layer of pre activated nodes\n",
    "            \n",
    "            act_node = relu(pre_node)            ## activate the nodes\n",
    "            \n",
    "        else:\n",
    "            pre_node = weighting @ np.array(act_node_dict[f'node_{counter-1}']).flatten()    ## create the next layer using previous activation, sometimes ould create nested array so convert to array then flatten\n",
    "            pre_node += bias_dict[f'bias_{counter}'].flatten()           ## add the bias to the next layer\n",
    "    \n",
    "            if counter == len(weighting_dict):\n",
    "                act_node = softmax(pre_node)           ## if final node use softmax activation\n",
    "            else:\n",
    "                act_node = relu(pre_node)              ## otherwise use relu activation\n",
    "\n",
    "    \n",
    "        pre_node_dict[f'node_{counter}'] = pre_node           ## Append each pre actiation node layer to dictionary\n",
    "        act_node_dict[f'node_{counter}'] = act_node           ## Append each activated node layer to dictionary\n",
    "\n",
    "        counter += 1                                  ## Increment counter for dictionary extractions\n",
    "\n",
    "    return(list(act_node_dict.values())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9557e-33fd-444d-b43a-f23c19072f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "76f7f487-7c4b-44a2-a412-aa39d9a83f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_hidden_layers = 3           ## number of hidden layers you want in network\n",
    "layer_sizes = [10, 10, 10]               ## number of nodes in the each layer\n",
    "prediction_metrics = ['venue code', 'gf_rolling', 'sot_rolling', 'xg_strength']\n",
    "max_goals = 7\n",
    "output_size = max_goals + 1\n",
    "\n",
    "###############################   Trainging loop with epochs  #################################\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(0,epochs):\n",
    "    \n",
    "    if epoch == 0:                  ## if first loop then run with no previous weighting or biases\n",
    "        weighting_dict, bias_dict = neural_network_processing(training_data, prediction_metrics, number_of_hidden_layers, layer_sizes,  #### first training process\n",
    "                                                            output_size, prev_weights=None, prev_biases=None)\n",
    "    else:                           ## otherwise loop back using previous weightings and biases\n",
    "        weighting_dict, bias_dict = neural_network_processing(training_data, prediction_metrics, number_of_hidden_layers, layer_sizes, \n",
    "                                                            output_size, prev_weights=weighting_dict, prev_biases=bias_dict)\n",
    "    \n",
    "final_weighting_dict = weighting_dict\n",
    "final_bias_dict = bias_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5333a34f-d479-4baa-b471-4a637a8e9cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:92   incorrect:248\n",
      "acc 0.27058823529411763\n"
     ]
    }
   ],
   "source": [
    "number_of_hidden_layers = 3           ## number of hidden layers you want in network\n",
    "layer_sizes = [10, 10, 10]               ## number of nodes in the each layer\n",
    "prediction_metrics = ['venue code', 'gf_rolling', 'sot_rolling', 'xg_strength']\n",
    "max_goals = 7\n",
    "output_size = max_goals + 1\n",
    "\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for index, row in testing_data.iterrows():     ## iterate through every row in the training data \n",
    "        \n",
    "    testing_data_row = row      ## only need the prediciton metrics from each row\n",
    "    \n",
    "    prediction_vector = forward_process(final_weighting_dict, final_bias_dict, testing_data_row, prediction_metrics)\n",
    "\n",
    "    predicted_goals = np.argmax(prediction_vector)\n",
    "    actual_goals = testing_data_row['gf']\n",
    "\n",
    "    #print(f'predicted:{predicted_goals}    actual:{actual_goals}')\n",
    "    #print(prediction_vector)\n",
    "    \n",
    "    if int(actual_goals) == predicted_goals:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "print(f'correct:{correct}   incorrect:{incorrect}')\n",
    "print('acc', correct/(len(testing_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9876f46c-dc5f-41ad-84d6-8d17d5d39be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1': array([[-0.05255854664267912, 0.0039466279510695455, 0.13597706087624634,\n",
       "         0.14537694395032283],\n",
       "        [0.23227731164840162, 0.17532107927484294, 0.1254219184237789,\n",
       "         0.13695210916036257],\n",
       "        [0.07659914030892996, 0.3115138780596014, 0.20620226178056703,\n",
       "         0.2812294668578852],\n",
       "        [-0.4962515165458805, -0.1860339528421563, -0.03100820653145913,\n",
       "         0.03482704909290382],\n",
       "        [-0.27014358798580695, 0.4734169028226971, -0.2292021623797349,\n",
       "         -0.13275707163995476],\n",
       "        [0.44656345889622456, 0.027957179745697655, -0.3370480318468005,\n",
       "         0.23466158405887277],\n",
       "        [0.43833567707175936, 0.12825766751398554, -0.3636421963168344,\n",
       "         0.0009173090612032011],\n",
       "        [0.6586711838889949, -0.20003731709232292, 0.19650271018012797,\n",
       "         0.38185835185731865],\n",
       "        [0.018334069581853463, 0.3363908430033967, -0.23184882400724272,\n",
       "         -0.04003123433817035],\n",
       "        [-0.4854384252829645, -0.5252913614593304, 0.14982131240444152,\n",
       "         0.12919658255937522]], dtype=object),\n",
       " 'layer_2': array([[-0.15388527513207498, -0.17865217269071984, -0.09781188140934041,\n",
       "         0.007139172485488132, -0.2079668783740043, 0.12760875790603418,\n",
       "         -0.32505228410087067, -0.05340686820745557, 0.11888802776848822,\n",
       "         0.21282002358186727],\n",
       "        [-0.16322067054681216, 0.09433788990881002, -0.29726070299979135,\n",
       "         0.26040697158290543, -0.2516708621525152, 0.00037273852451723234,\n",
       "         -0.17633719943995563, 0.12079913959649864, -0.08466841913278819,\n",
       "         0.006286961272619033],\n",
       "        [0.061202831898092586, 0.2764699627768524, 0.2694730453737008,\n",
       "         -0.24964655595742902, 0.05568211108555743, 0.07141249018544525,\n",
       "         0.04652299833926457, 0.5147250165689713, 0.1576222889540188,\n",
       "         -0.06933712976894103],\n",
       "        [-0.01107633884248175, 0.08915528477903759, -0.06020263366080419,\n",
       "         0.11933594026911307, -0.19162546137648584, 0.15759547435555826,\n",
       "         0.11346906613889164, -0.18652706601008343, 0.10017620708164675,\n",
       "         0.07568571950082632],\n",
       "        [-0.21026406665153338, -0.023519356350857144, 0.16310220822565846,\n",
       "         0.3485216195350394, 0.13733573949605635, 0.08899021610332053,\n",
       "         0.31279413456297683, -0.29102919662673626, 0.28337728178098115,\n",
       "         0.11692668717505551],\n",
       "        [0.07703517120442421, -0.19562237276663313,\n",
       "         -0.0019607107924786704, -0.25722722298847617,\n",
       "         0.28409703876456466, 0.05449285819436922, 0.17615214455477501,\n",
       "         -0.08114302803799162, 0.17252482008835457, -0.24349346910171799],\n",
       "        [-0.06838565757345838, -0.27960694930511454, 0.049911718319165244,\n",
       "         -0.2007330892834328, 0.11543133307044773, 0.08578570462170321,\n",
       "         0.31241485288214915, 0.037685417862574955, -0.04879532819464816,\n",
       "         -0.058454491130104924],\n",
       "        [0.11762811820666969, 0.09539406771821836, -0.32422009310130523,\n",
       "         0.28012475594095576, -0.07535157936697622, 0.32629101550345313,\n",
       "         0.30269830781089296, 0.16862294627780142, 0.33491611307320834,\n",
       "         -0.22614833841774806],\n",
       "        [0.12575084790582527, -0.11433121705127287, -0.08540030493506003,\n",
       "         0.09894177201706561, 0.14308682145562981, -0.29464309610177375,\n",
       "         0.26671419448779043, -0.008007949022133106, 0.07069780083624913,\n",
       "         -0.24232327696706343],\n",
       "        [0.1326946101852752, 0.07133208603981955, 0.2667183660810651,\n",
       "         -0.505883177721338, -0.028267701458001216, 0.31385277103616727,\n",
       "         0.13234849128749376, 0.16515434370202559, 0.2423597347044559,\n",
       "         -0.3146237637600877]], dtype=object),\n",
       " 'layer_3': array([[0.7743454741667726, 0.4328750295975805, -0.48376559850652967,\n",
       "         0.21832541596417315, 0.5863457103016625, 0.5184743622356583,\n",
       "         0.7288896368593446, 0.022650373260184646, 0.2996330898264581,\n",
       "         -0.25005034883889465],\n",
       "        [0.613668537108919, 0.3175242765183588, -0.33872741634758086,\n",
       "         0.5182642519099999, 0.44775766678595175, 0.10029221484016551,\n",
       "         0.3215312891661982, -0.05326494789411694, -0.08467268523873478,\n",
       "         -0.19884317033575383],\n",
       "        [-0.28241059453781747, -0.26129211135939623, -0.1410882338890701,\n",
       "         0.0660531674892742, 0.08852616727557581, 0.17281059944279295,\n",
       "         0.34124609026084446, 0.22497564449116275, -0.019018455725450422,\n",
       "         -0.18003003419548533],\n",
       "        [0.0265052179032007, 0.010335508482839484, -0.24344942977391384,\n",
       "         0.044821941344970924, 0.02723372106434455, 0.32649193707225294,\n",
       "         0.28373628057004296, -0.16242020304220786, 0.2642131577529956,\n",
       "         0.020972564172454196],\n",
       "        [0.031113424101752832, -0.2289698423316666, -0.24125514048172578,\n",
       "         -0.0016378401014215194, 0.13896325972750467, 0.05276587754331792,\n",
       "         -0.023318439758037202, -0.05443036601472293, 0.2427424986789325,\n",
       "         -0.2835305709331993],\n",
       "        [-0.24133846871292938, -0.016877247905188957,\n",
       "         -0.08028841308518311, -0.010424572759491187, 0.24852751280392749,\n",
       "         0.3915430601386052, 0.18729545251784113, -0.19588572715719466,\n",
       "         -0.010570193296899818, 0.11175387123732462],\n",
       "        [0.008911066337768043, -0.08593550383935689, -0.08449975190840824,\n",
       "         -0.20741142081701872, 0.32554927602467837, -0.13218720630531433,\n",
       "         0.320010594797942, -0.1451281736681372, 0.20747587830234046,\n",
       "         0.011638303915388842],\n",
       "        [-0.24601262946928049, -0.04088134634298075, -0.2883409535878573,\n",
       "         0.02301027128714356, -0.21341315285175433, -0.23181173949979497,\n",
       "         -0.2883039680271607, -0.2184874109089864, 0.27855133932495185,\n",
       "         -0.11812858304617121],\n",
       "        [-0.13010938385357268, -0.11855135445270165, -0.07860198577058283,\n",
       "         0.07038675710016025, 0.0989104963039664, -0.06767464792391881,\n",
       "         0.11292484226388963, 0.03959567413264326, 0.3399148886547015,\n",
       "         -0.0023530306477953155],\n",
       "        [0.1241746738464224, 0.17877411063367138, -0.14844124177723658,\n",
       "         0.06765832018616327, -0.26937204295630107, -0.02759620377094871,\n",
       "         0.07022942730740318, 0.048556772009525045, 0.030131326975268873,\n",
       "         0.11444408154504655]], dtype=object),\n",
       " 'layer_4': array([[26.34185597322832, 19.565870039961403, 10.140377727588834,\n",
       "         10.058349375532439, 17.491924831936164, 0.4741783910930605,\n",
       "         3.3254997852750803, 15.14040406040427, 3.1447299445529278,\n",
       "         3.2396722857776257],\n",
       "        [16.580620240251907, 12.200384790794308, 6.3895408502546855,\n",
       "         6.1113602475391, 10.054948944599635, 0.0993375084601785,\n",
       "         1.9375793133161976, 9.027816141709408, 2.222594261939782,\n",
       "         2.419976329217676],\n",
       "        [-8.67370382807122, -6.520211601149107, -3.9797521713065453,\n",
       "         -3.8473181888451244, -7.20906186141692, -0.9711728730846112,\n",
       "         -1.7509181700338412, -5.980278232735152, -1.6432270984122306,\n",
       "         -1.1891940273455581],\n",
       "        [-10.018297892302604, -7.302351425545482, -4.4182405865120495,\n",
       "         -4.187440792276407, -7.475579893289152, -0.294357306620755,\n",
       "         -1.6512150855036194, -6.202347937155735, -1.3835159116164495,\n",
       "         -1.6123225134732597],\n",
       "        [-16.293217596537843, -11.740255969939872, -6.609031056895049,\n",
       "         -6.195035199059765, -11.201071555752868, -0.5706633714237281,\n",
       "         -2.3085665866858434, -9.661464302080956, -2.206179999828925,\n",
       "         -2.222833866514234],\n",
       "        [-4.727238980906904, -3.7008226727892137, -1.6740290584903896,\n",
       "         -1.4758732141585196, -2.287815346620158, 0.3604433173757314,\n",
       "         -0.5110616657828573, -2.3520932348095167, -0.28497502683772297,\n",
       "         -0.6942308336242557],\n",
       "        [-4.038671739283961, -3.1145089047475594, -1.4327785973178409,\n",
       "         -1.3020144036000922, -1.9662105137505537, 0.4326380779396896,\n",
       "         0.09675101017486562, -1.2213685245266241, -0.17624110752923028,\n",
       "         -0.6398530693601057],\n",
       "        [0.8321193043796861, 0.263547864346046, 0.9929766166079477,\n",
       "         1.2969078142991093, 2.0756763001119434, 0.7995411462579732,\n",
       "         0.4700474156508994, 1.8759596236829585, 1.0370124941667003,\n",
       "         0.16340115523647586]], dtype=object)}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighting_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b88bd718-25d6-464c-ad4b-bcff3c4a2cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP = MLPClassifier(hidden_layer_sizes=(10,10), max_iter=1000)\n",
    "MLP.fit(training_data[prediction_metrics], training_data['gf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e19c3fcb-df28-4cbb-b75f-ad8b84054169",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = MLP.predict(testing_data[prediction_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "95f50396-55fe-4820-9b90-d4cac4abfc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.28      0.29      0.28        76\n",
      "         1.0       0.35      0.44      0.39       111\n",
      "         2.0       0.30      0.38      0.34        92\n",
      "         3.0       0.00      0.00      0.00        39\n",
      "         4.0       0.00      0.00      0.00        13\n",
      "         5.0       0.00      0.00      0.00         6\n",
      "         6.0       0.00      0.00      0.00         2\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.31       340\n",
      "   macro avg       0.12      0.14      0.13       340\n",
      "weighted avg       0.26      0.31      0.28       340\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\joshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\joshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions\n",
    "\n",
    "\n",
    "print(classification_report( (testing_data['gf']) , predictions) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ddc7d238-ccf6-4c80-8ca6-871be6394ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.31176470588235294\n"
     ]
    }
   ],
   "source": [
    "x = testing_data['gf'] - predictions\n",
    "#x.ndims(1,)\n",
    "x = np.array(x)\n",
    "correct = len(np.where(x==0)[0])\n",
    "total = len(testing_data)\n",
    "\n",
    "print('acc',correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33cc522-94ed-4b20-b5cc-02d11b9cdb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e22e58b-f66a-4ad6-8158-50a9feddc02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nweightings_serializable = {key: value.tolist() for key, value in final_weighting_dict.items()}\\nbiases_serializable = {key: value.tolist() for key, value in final_bias_dict.items()}\\n\\n\\nwith open(\"final weightings.json\", \"w\") as f:\\n    json.dump(weightings_serializable, f)\\n\\nwith open(\"final biases.json\", \"w\") as f:\\n    json.dump(biases_serializable, f)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "'''\n",
    "weightings_serializable = {key: value.tolist() for key, value in final_weighting_dict.items()}\n",
    "biases_serializable = {key: value.tolist() for key, value in final_bias_dict.items()}\n",
    "\n",
    "\n",
    "with open(\"final weightings.json\", \"w\") as f:\n",
    "    json.dump(weightings_serializable, f)\n",
    "\n",
    "with open(\"final biases.json\", \"w\") as f:\n",
    "    json.dump(biases_serializable, f)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce85fc85-77c8-4571-93f8-cc796ea291b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final weightings.json\", \"r\") as f:\n",
    "    weights_loaded_data = json.load(f)\n",
    "\n",
    "with open(\"final biases.json\", \"r\") as f:\n",
    "    biases_loaded_data = json.load(f)\n",
    "\n",
    "\n",
    "weights_loaded_data = {key: np.array(value) for key, value in weights_loaded_data.items()}        \n",
    "biases_loaded_data = {key: np.array(value) for key, value in biases_loaded_data.items()}    \n",
    "\n",
    "\n",
    "#weights_loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5a7335-8124-4f44-90e8-bc10778ee1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "091f8ac8-4fb3-46c7-be3d-aec6378e3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_weighting_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d62df-cdb4-4a6b-bc0c-7007b3670e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da1737-661e-4844-a01c-7f7259e68676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
