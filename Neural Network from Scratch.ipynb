{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afedad5a-4b4b-4b0c-b363-482e1dbba284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_avg(group, cols, new_cols):  ## takes small df for a single team and adds rolling avgs to df\n",
    "\n",
    "    group = group.sort_values('date')\n",
    "    rolling_stats = group[cols].rolling(3,closed='left').mean()   ## last x averaged\n",
    "    group[new_cols] = rolling_stats\n",
    "    group = group.dropna(subset=new_cols)\n",
    "    return group\n",
    "\n",
    "\n",
    "def create_acronym(name, length=3):\n",
    "    words = name.split()\n",
    "    acronym = ''.join(word[:length].upper() for word in words)  \n",
    "    return acronym[:length]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "333ebdfd-e928-4b8d-9f9d-38a02ab86ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "############################################### PREPARING DATA ###############################################\n",
    "\n",
    "\n",
    "data_23 = pd.read_csv('matches3.csv')\n",
    "data_24 = pd.read_csv('matches4.csv')\n",
    "full_data = pd.concat([data_23, data_24])\n",
    "\n",
    "\n",
    "team_list_2324 = data_23['team'].unique()            ###   List of all the teams from 2023-24 season\n",
    "team_list_2425 = data_24['team'].unique()            ###   List of all the teams from 2024-25 season\n",
    "shared_teams = np.intersect1d(team_list_2324, team_list_2425)\n",
    "\n",
    "\n",
    "team_name_mapping = {\n",
    "    \"Manchester Utd\": \"Manchester United\",\n",
    "    \"Nott'ham Forest\": \"Nottingham Forest\", \n",
    "    \"Wolves\": \"Wolverhampton Wanderers\", \n",
    "    \"Tottenham\": \"Tottenham Hotspur\", \n",
    "    \"West Ham\": \"West Ham United\", \n",
    "    \"Brighton\": \"Brighton and Hove Albion\", \n",
    "    \"Newcastle Utd\": \"Newcastle United\",  }\n",
    "\n",
    "full_data['opponent'] = full_data['opponent'].replace(team_name_mapping)\n",
    "\n",
    "\n",
    "filt_full_data = full_data[full_data['team'].isin(shared_teams) & full_data['opponent'].isin(shared_teams)] ## Removes any fixtures with promoted/relagated teams\n",
    "filt_full_data = filt_full_data[['date','team','opponent','gf','ga','xg','xga','sot','pk','fk','venue','poss']]    ## Useful cols\n",
    "filt_full_data['venue code'] = filt_full_data.loc[:,'venue'].astype('category').cat.codes  ## Makes Home/Away binary                  \n",
    "filt_full_data = filt_full_data.reset_index()\n",
    "\n",
    "\n",
    "cols = ['gf','ga','xg','xga','sot','poss']    ## cols we want to add rolling stats to\n",
    "new_cols = [f'{x}_rolling' for x in cols]    ## adds rolling suffic to each stat in column\n",
    "\n",
    "\n",
    "grouped_matches = filt_full_data.groupby('team')              ## all the matches grouped by team\n",
    "rolling_df = grouped_matches.apply(lambda x : rolling_avg(x, cols, new_cols), include_groups=False).reset_index()    ## applying rolling averages to each group in the df. reset index keeps \"team\" as col header\n",
    "\n",
    "### We also want the roling stats for the away team so need to create a new df and then merge together\n",
    "\n",
    "opponent_stats = rolling_df.copy()\n",
    "opponent_stats = opponent_stats.rename(columns={'opponent':'OP', 'team':'opponent', 'ga_rolling': 'opp_ga_rolling', 'gf_rolling':'opp_gf_rolling', 'xg_rolling': 'opp_xg_rolling', 'xga_rolling':'opp_xga_rolling', 'sot_rolling':'opp_sot_rolling'})\n",
    "opponent_stats = opponent_stats[['date', 'opponent', 'opp_ga_rolling', 'opp_gf_rolling', 'opp_xg_rolling', 'opp_xga_rolling','opp_sot_rolling']]\n",
    "\n",
    "\n",
    "rolling_df = rolling_df.merge(opponent_stats, left_on=['opponent', 'date'], right_on=['opponent', 'date']) ## Merge with opponent stats\n",
    "\n",
    "rolling_df['xg_strength'] = rolling_df['xg_rolling'] + rolling_df['opp_xga_rolling']   ## High value -> expect goals\n",
    "#rolling_df['xga_weakness'] = rolling_df['xga_rolling'] + rolling_df['opp_xg_rolling']\n",
    "\n",
    "rolling_df['xg_ratio'] = (rolling_df['xg_rolling']) / (rolling_df['opp_xga_rolling'] + 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08ce0bca-236d-48c0-86e4-a5c6e50711a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = rolling_df[rolling_df['date'] < '2024-06-01']   ## Training data from before date\n",
    "testing_data = rolling_df[rolling_df['date'] > '2024-06-01']    ## Testing data after date\n",
    "\n",
    "prediction_metrics = ['venue code', 'gf_rolling', 'sot_rolling', 'xg_strength']\n",
    "#prediction_metrics = ['venue code', 'xg_strength']\n",
    "#prediction_metrics = ['venue code',  'gf_rolling', 'sot_rolling']\n",
    "#prediction_metrics = ['gf_rolling']\n",
    "#prediction_metrics = ['xg_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b742b-d9d4-44bd-913a-d9d0563a80b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713638e-2936-402b-80a1-b48668b97862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a3b33a-8d90-423f-9fff-6cfefb87a3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2800d9-bd14-4868-a666-7a8b4bd04742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cdbc4aa-b907-42e6-b730-4e746f5dd511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "\n",
    "#################    Sigmoid function noramlises results between 0 - 1    #################\n",
    "def sigmoid(x):\n",
    "    S = 1 / (1+np.exp(-x))\n",
    "    return(S)\n",
    "\n",
    "#################    Softmax function noramlises results between 0 - P    #################\n",
    "def softmax(x):\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    sigma = np.exp(x) / sum(np.exp(x))\n",
    "    return(sigma)\n",
    "\n",
    "def relu(z):\n",
    "    out = np.maximum(0, z)\n",
    "    return(out)\n",
    "    \n",
    "def relu_derivative(y):\n",
    "    out = (y>0).astype(float)\n",
    "    return(out)\n",
    "\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    return np.where(x > 0, x, alpha * x)  # Allows small negative values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa178ba-6b30-4122-b4d5-e6700b3ae99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5967b35b-df82-4cf8-ba84-695674991a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e3609ff-aa72-47ba-bb3e-4556881cc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_initialisation(number_of_hidden_layers, layer_sizes, input_size, output_size):\n",
    "\n",
    "    if len(layer_sizes) != number_of_hidden_layers:\n",
    "        print(f'layer sizes:{len(layer_sizes)}', f'number of layers:{number_of_hidden_layers}')\n",
    "        raise Exception(\"layer sizes must equal number of hidden layers\")\n",
    "        \n",
    "    layer_sizes.append(output_size)      ## adds the output number of nodes to list of layer sizes\n",
    "    \n",
    "    ############# Creating initial weighting matrixes and biases ###############\n",
    "    \n",
    "    weighting_dict = {}                                             ## \n",
    "    bias_dict = {}                                               ## holds all the biases\n",
    "    for i in range(0, number_of_hidden_layers+1):                ## iterates through each possible layer connection\n",
    "    \n",
    "        if i == 0:          ## creating the first layer\n",
    "            xavier_weight_mat = np.random.uniform(-1/np.sqrt(input_size),1/np.sqrt(input_size), (layer_sizes[i], input_size))    ## xavier distribution    https://www.geeksforgeeks.org/xavier-initialization/\n",
    "        elif i < number_of_hidden_layers+2:  ## creating the middle layers\n",
    "            xavier_weight_mat = np.random.uniform(-1/np.sqrt(layer_sizes[i]),1/np.sqrt(layer_sizes[i]), (layer_sizes[i], layer_sizes[i-1]))\n",
    "       \n",
    "        bias = np.zeros((layer_sizes[i],1))\n",
    "        weighting_dict[f'layer_{i+1}'] = xavier_weight_mat      ## Appends the rand matrix to the layers dictionary\n",
    "        bias_dict[f'bias_{i+1}'] = bias\n",
    "    \n",
    "    return(weighting_dict, bias_dict)\n",
    "\n",
    "def node_activations(weighting_dict, bias_dict, training_data_row, prediction_metrics):\n",
    "\n",
    "    input_vector = training_data_row[prediction_metrics]\n",
    "    \n",
    "    pre_node_dict = {}                                 ## Creates empty dictionary for the pre node layers\n",
    "    act_node_dict = {}                                 ## Creates empty dictionary for the active node layers\n",
    "    counter = 1                                        ## Initialsies counter for calling dictionary items\n",
    "\n",
    "    pre_node_dict[f'node_0'] = input_vector  \n",
    "    \n",
    "    for item, weighting in weighting_dict.items():     ## item is the name of the dictionary item, value is the matrix assigned to the item\n",
    "       \n",
    "        if counter == 1:                               ## this deals with creating the first layer from input layer\n",
    "            pre_node = weighting @ input_vector        ## create the first layer \n",
    "            pre_node += bias_dict[f'bias_{counter}'].flatten()   ## add the bias to the first layer of pre activated nodes\n",
    "            \n",
    "            act_node = relu(pre_node)            ## activate the nodes\n",
    "            \n",
    "        else:\n",
    "            pre_node = weighting @ np.array(act_node_dict[f'node_{counter-1}']).flatten()    ## create the next layer using previous activation, sometimes ould create nested array so convert to array then flatten\n",
    "            pre_node += bias_dict[f'bias_{counter}'].flatten()           ## add the bias to the next layer\n",
    "    \n",
    "            if counter == len(weighting_dict):\n",
    "                act_node = softmax(pre_node)           ## if final node use softmax activation\n",
    "            else:\n",
    "                act_node = relu(pre_node)              ## otherwise use relu activation\n",
    "\n",
    "        pre_node_dict[f'node_{counter}'] = pre_node           ## Append each pre actiation node layer to dictionary\n",
    "        act_node_dict[f'node_{counter}'] = act_node           ## Append each activated node layer to dictionary\n",
    "    \n",
    "        counter += 1                                  ## Increment counter for dictionary extractions\n",
    "    \n",
    "    return(pre_node_dict, act_node_dict, bias_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b50a088e-dbf3-4c9e-ad03-7f15b4a35017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(training_data_row, weighting_dict, bias_dict, pre_node_dict, act_node_dict, output_size, learning_rate=0.0001):\n",
    "\n",
    "    blank = np.zeros((output_size,1))                 ## array of zeros of same size as output array\n",
    "    true = blank.copy()                               ## copy array of zeros\n",
    "    true[int(training_data_row['gf']), 0] = 1         ## creates vector of actual goals scored\n",
    "\n",
    "    ######################################### updating the weights #########################################\n",
    "    \n",
    "    alpha = learning_rate             ## alpha is set to the learning rate\n",
    "    count = len(weighting_dict)       ## initiasing count at max value\n",
    "    output = list(act_node_dict.values())[-1]\n",
    "    \n",
    "    updated_weighting_dict = {}\n",
    "    updated_bias_dict = {}\n",
    "    \n",
    "    for i in range(count,0,-1):\n",
    "        \n",
    "        if count == len(weighting_dict):           ## for the inital backpropagation from output layer\n",
    "            dl_dz =  output - true.flatten()       ## gradient wrt logits for softmax + CE loss\n",
    "        else:\n",
    "     \n",
    "            dl_dz = np.transpose(weighting_dict[f'layer_{count+1}']) @ dl_dz              ## first step of loss \n",
    "            dl_dz = np.multiply(dl_dz , relu_derivative(pre_node_dict[f'node_{count}']))  ## second step of element wise                         \n",
    "\n",
    "        if dl_dz.ndim == 1:                              ## if only 1 dimensional               \n",
    "            dl_dz = np.expand_dims(dl_dz, axis=1)        ## makes sure that its of the form (x,1) rather than (8,)\n",
    "\n",
    "        dl_db = dl_dz                 ##  biases independent of input activation so same as loss to pre node values\n",
    "        pre_node_dict[f'node_{count-1}'] = np.expand_dims(pre_node_dict[f'node_{count-1}'], axis =1)   ## dealing with array formatting\n",
    "        \n",
    "        dummy_weighting = weighting_dict[f'layer_{count}'] - alpha * (dl_dz @ np.transpose(pre_node_dict[f'node_{count-1}']) )   ## W = W - a*(dL/dW) = W - a*loss*input_into_node\n",
    "        dummy_bias = bias_dict[f'bias_{count}'] - alpha * dl_db    ## Create new updated bias\n",
    "    \n",
    "        updated_weighting_dict[f'layer_{count}'] = dummy_weighting     ## update the old weighting with the new weighting\n",
    "        updated_bias_dict[f'bias_{count}'] = dummy_bias               ## update the old bias with the new bias\n",
    " \n",
    "        count -= 1    ## increment the count by -1 to\n",
    "    \n",
    "    weighting_dict.update(updated_weighting_dict)     ## update the old weighting dictionary with the new dictionary\n",
    "    bias_dict.update(updated_bias_dict)               ## update the old bias dictionary with the new dictionary\n",
    "    \n",
    "    \n",
    "    return(weighting_dict, bias_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0381ace6-5d8d-4023-8e43-fcaf7ceaa6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Each metric in the first layer is multiplied by the corresponding component for a weighting veector for each node ##\n",
    "## If we have 5 metrics and 10 first layer nodes then we need 10 vectors of size 5 ##\n",
    "## The first component of each of these 10 metrics contributes to the magnitude fo the first node, and so on ##\n",
    "## We need to start the initial vectors in some random state, limiting magnitudes of components to prevent vanishing/exploding ##\n",
    "\n",
    "\n",
    "def neural_network_processing(training_data, prediction_metrics, number_of_hidden_layers, layer_sizes, output_size, prev_weights=None, prev_biases=None):\n",
    "\n",
    "    input_size = len(prediction_metrics)\n",
    "\n",
    "    if (prev_weights == None) and (prev_biases == None):          ## run initilisation if no existing weights exist\n",
    "        weighting_dict, bias_dict = layer_initialisation(number_of_hidden_layers, layer_sizes, input_size, output_size)\n",
    "    else:                \n",
    "        weighting_dict, bias_dict = prev_weights, prev_biases    \n",
    "\n",
    "    for index, row in training_data.iterrows():     ## iterate through every row in the training data \n",
    "    \n",
    "        training_data_row = row  ## only need the prediciton metrics from each row    \n",
    "        pre_node_dict, act_node_dict, bias_dict = node_activations(weighting_dict, bias_dict, training_data_row, prediction_metrics) ## activate the nodes\n",
    "        weighting_dict, bias_dict = backpropagation(training_data_row, weighting_dict, bias_dict, pre_node_dict, act_node_dict, output_size, learning_rate=0.1) ## use backpropagation to update the weightings    \n",
    "\n",
    "    return(weighting_dict, bias_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf4bfb3a-89c7-4ffb-b37e-fb091637ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_process(weighting_dict, bias_dict, testing_data_row, prediction_metrics):\n",
    "\n",
    "    input_vector = testing_data_row[prediction_metrics]\n",
    "    \n",
    "    pre_node_dict = {}                                 ## Creates empty dictionary for the pre node layers\n",
    "    act_node_dict = {}                                 ## Creates empty dictionary for the active node layers\n",
    "    counter = 1                                        ## Initialsies counter for calling dictionary items\n",
    "\n",
    "    pre_node_dict[f'node_0'] = input_vector  \n",
    "    \n",
    "    for item, weighting in weighting_dict.items():     ## item is the name of the dictionary item, value is the matrix assigned to the item\n",
    "        \n",
    "        if counter == 1:                               ## this deals with creating the first layer from input layer\n",
    "            pre_node = weighting @ input_vector        ## create the first layer \n",
    "            pre_node += bias_dict[f'bias_{counter}'].flatten()   ## add the bias to the first layer of pre activated nodes\n",
    "            \n",
    "            act_node = relu(pre_node)            ## activate the nodes\n",
    "            \n",
    "        else:\n",
    "            pre_node = weighting @ np.array(act_node_dict[f'node_{counter-1}']).flatten()    ## create the next layer using previous activation, sometimes ould create nested array so convert to array then flatten\n",
    "            pre_node += bias_dict[f'bias_{counter}'].flatten()           ## add the bias to the next layer\n",
    "    \n",
    "            if counter == len(weighting_dict):\n",
    "                act_node = softmax(pre_node)           ## if final node use softmax activation\n",
    "            else:\n",
    "                act_node = relu(pre_node)              ## otherwise use relu activation\n",
    "\n",
    "    \n",
    "        pre_node_dict[f'node_{counter}'] = pre_node           ## Append each pre actiation node layer to dictionary\n",
    "        act_node_dict[f'node_{counter}'] = act_node           ## Append each activated node layer to dictionary\n",
    "\n",
    "        counter += 1                                  ## Increment counter for dictionary extractions\n",
    "\n",
    "    return(list(act_node_dict.values())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9557e-33fd-444d-b43a-f23c19072f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76f7f487-7c4b-44a2-a412-aa39d9a83f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_hidden_layers = 3           ## number of hidden layers you want in network\n",
    "layer_sizes = [10, 10, 10]               ## number of nodes in the each layer\n",
    "prediction_metrics = ['venue code', 'gf_rolling', 'sot_rolling', 'xg_strength']\n",
    "max_goals = 7\n",
    "output_size = max_goals + 1\n",
    "\n",
    "###############################   Trainging loop with epochs  #################################\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(0,epochs):\n",
    "    \n",
    "    if epoch == 0:                  ## if first loop then run with no previous weighting or biases\n",
    "        weighting_dict, bias_dict = neural_network_processing(training_data, prediction_metrics, number_of_hidden_layers, layer_sizes,  #### first training process\n",
    "                                                            output_size, prev_weights=None, prev_biases=None)\n",
    "    else:                           ## otherwise loop back using previous weightings and biases\n",
    "        weighting_dict, bias_dict = neural_network_processing(training_data, prediction_metrics, number_of_hidden_layers, layer_sizes, \n",
    "                                                            output_size, prev_weights=weighting_dict, prev_biases=bias_dict)\n",
    "    \n",
    "final_weighting_dict = weighting_dict\n",
    "final_bias_dict = bias_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5333a34f-d479-4baa-b471-4a637a8e9cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:93   incorrect:247\n",
      "acc 0.2735294117647059\n"
     ]
    }
   ],
   "source": [
    "number_of_hidden_layers = 3           ## number of hidden layers you want in network\n",
    "layer_sizes = [10, 10, 10]               ## number of nodes in the each layer\n",
    "prediction_metrics = ['venue code', 'gf_rolling', 'sot_rolling', 'xg_strength']\n",
    "max_goals = 7\n",
    "output_size = max_goals + 1\n",
    "\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for index, row in testing_data.iterrows():     ## iterate through every row in the training data \n",
    "        \n",
    "    testing_data_row = row      ## only need the prediciton metrics from each row\n",
    "    \n",
    "    prediction_vector = forward_process(final_weighting_dict, final_bias_dict, testing_data_row, prediction_metrics)\n",
    "\n",
    "    predicted_goals = np.argmax(prediction_vector)\n",
    "    actual_goals = testing_data_row['gf']\n",
    "\n",
    "    #print(f'predicted:{predicted_goals}    actual:{actual_goals}')\n",
    "    #print(prediction_vector)\n",
    "    \n",
    "    if int(actual_goals) == predicted_goals:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1\n",
    "print(f'correct:{correct}   incorrect:{incorrect}')\n",
    "print('acc', correct/(len(testing_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876f46c-dc5f-41ad-84d6-8d17d5d39be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b88bd718-25d6-464c-ad4b-bcff3c4a2cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP = MLPClassifier(hidden_layer_sizes=(10,10), max_iter=1000)\n",
    "MLP.fit(training_data[prediction_metrics], training_data['gf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e19c3fcb-df28-4cbb-b75f-ad8b84054169",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = MLP.predict(testing_data[prediction_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95f50396-55fe-4820-9b90-d4cac4abfc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.09      0.14        76\n",
      "         1.0       0.31      0.59      0.40       111\n",
      "         2.0       0.24      0.22      0.23        92\n",
      "         3.0       0.17      0.08      0.11        39\n",
      "         4.0       0.00      0.00      0.00        13\n",
      "         5.0       0.00      0.00      0.00         6\n",
      "         6.0       0.00      0.00      0.00         2\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.28       340\n",
      "   macro avg       0.13      0.12      0.11       340\n",
      "weighted avg       0.26      0.28      0.24       340\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\joshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\joshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions\n",
    "\n",
    "\n",
    "print(classification_report( (testing_data['gf']) , predictions) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddc7d238-ccf6-4c80-8ca6-871be6394ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.2823529411764706\n"
     ]
    }
   ],
   "source": [
    "x = testing_data['gf'] - predictions\n",
    "#x.ndims(1,)\n",
    "x = np.array(x)\n",
    "correct = len(np.where(x==0)[0])\n",
    "total = len(testing_data)\n",
    "\n",
    "print('acc',correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33cc522-94ed-4b20-b5cc-02d11b9cdb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e22e58b-f66a-4ad6-8158-50a9feddc02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nweightings_serializable = {key: value.tolist() for key, value in final_weighting_dict.items()}\\nbiases_serializable = {key: value.tolist() for key, value in final_bias_dict.items()}\\n\\n\\nwith open(\"final weightings.json\", \"w\") as f:\\n    json.dump(weightings_serializable, f)\\n\\nwith open(\"final biases.json\", \"w\") as f:\\n    json.dump(biases_serializable, f)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "'''\n",
    "weightings_serializable = {key: value.tolist() for key, value in final_weighting_dict.items()}\n",
    "biases_serializable = {key: value.tolist() for key, value in final_bias_dict.items()}\n",
    "\n",
    "\n",
    "with open(\"final weightings.json\", \"w\") as f:\n",
    "    json.dump(weightings_serializable, f)\n",
    "\n",
    "with open(\"final biases.json\", \"w\") as f:\n",
    "    json.dump(biases_serializable, f)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce85fc85-77c8-4571-93f8-cc796ea291b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final weightings.json\", \"r\") as f:\n",
    "    weights_loaded_data = json.load(f)\n",
    "\n",
    "with open(\"final biases.json\", \"r\") as f:\n",
    "    biases_loaded_data = json.load(f)\n",
    "\n",
    "\n",
    "weights_loaded_data = {key: np.array(value) for key, value in weights_loaded_data.items()}        \n",
    "biases_loaded_data = {key: np.array(value) for key, value in biases_loaded_data.items()}    \n",
    "\n",
    "\n",
    "#weights_loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5a7335-8124-4f44-90e8-bc10778ee1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "091f8ac8-4fb3-46c7-be3d-aec6378e3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_weighting_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d62df-cdb4-4a6b-bc0c-7007b3670e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
